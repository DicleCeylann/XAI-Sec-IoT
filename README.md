# XAI-Sec-IoT: Explainable AI for Smart IoT Security Decisions ğŸ§ ğŸ”

This project introduces an explainable AI (XAI) framework for anomaly detection in smart city IoT sensor environments. It combines unsupervised machine learning with SHAP-based model explainability to enhance transparency in security decisions, aligning with the human-centered AI paradigm.

---

## ğŸŒ Overview

With the increasing deployment of IoT devices in critical infrastructures, ensuring reliable and interpretable security systems is essential. This project simulates realistic sensor logs, detects anomalies using Isolation Forest, and explains each decision with SHAP to empower system operators and decision makers with understandable insights.

---

## âœ… Key Features

- ğŸ” Synthetic sensor data generation (temperature, humidity, motion)
- ğŸ§ª Anomaly labeling via domain specific rules
- ğŸŒ² Unsupervised anomaly detection using Isolation Forest
- ğŸ” Explainable AI integration with SHAP
- ğŸ“Š Summary and individual decision visualizations
- ğŸ“ Clean project structure for research portfolios and academic use

---

## ğŸ“Š Dataset Description

| Column         | Description                                |
|----------------|--------------------------------------------|
| `timestamp`    | Time log of the sensor reading             |
| `sensor_id`    | Unique identifier for each sensor          |
| `temperature`  | Recorded temperature (Â°C)                  |
| `humidity`     | Recorded humidity level (%)                |
| `motion`       | Motion detected (0 = no, 1 = yes)          |
| `anomaly_flag` | Labeled anomaly (based on defined rules)   |
| `anomaly_pred` | Model-predicted anomaly (0 = normal, 1 = anomaly) |

---

## ğŸ§  Tech Stack

- Python 3.8+
- Pandas, NumPy
- Scikit-learn (Isolation Forest)
- SHAP (TreeExplainer)
- Matplotlib

---

## ğŸ“ˆ Example Outputs

### ğŸ”¹ SHAP Summary Plot  
Shows which features (e.g., temperature, humidity, motion) had the greatest influence on the modelâ€™s anomaly predictions across the dataset.  
Used to assess global feature importance.

### ğŸ”¹ SHAP Waterfall Plot  
Explains how each feature contributed to a single anomaly prediction.  
Used to understand the reasoning behind one specific decision made by the model.


---


## ğŸ‘©â€ğŸ’» Author

**Dicle Ceylan**
B.Sc. in Statistics, Yildiz Technical University (Class of 2026)  
Interested in AI, Cybersecurity, and IoT Security  
ğŸŒ GitHub: github.com/DicleCeylann 
ğŸ’¼ LinkedIn: linkedin.com/in/dicle-ceylan


---

ğŸ“„ License & Usage

This project is open source and can be freely used for academic, educational, or research purposes. If you build upon this work, please credit the repository.
